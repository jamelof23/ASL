{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "PrivAI.ipynb",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYeX7ur0v+oA8wr+V9oHxi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamelof23/ASL/blob/main/PrivAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Codebase and Models"
      ],
      "metadata": {
        "id": "iXIucaWWpoVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'interfacegan'\n",
        "!git clone https://github.com/genforce/interfacegan.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "!wget https://www.dropbox.com/s/qyv37eaobnow7fu/stylegan_ffhq.pth?dl=1 -O models/pretrain/stylegan_ffhq.pth --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyMo0VCfprkA",
        "outputId": "b2578caa-29be-454e-a57e-1c021a568ee6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'interfacegan'...\n",
            "remote: Enumerating objects: 613, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 613 (delta 94), reused 92 (delta 92), pack-reused 489 (from 1)\u001b[K\n",
            "Receiving objects: 100% (613/613), 13.72 MiB | 15.08 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Utility Functions"
      ],
      "metadata": {
        "id": "XpgN0pa0pwg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import io\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL.Image\n",
        "\n",
        "import torch\n",
        "\n",
        "# A dictionary containing information about the models available (e.g., pggan, stylegan).\n",
        "from models.model_settings import MODEL_POOL\n",
        "\n",
        "from models.stylegan_generator import StyleGANGenerator\n",
        "\n",
        "\n",
        "\n",
        "def build_generator(model_name):\n",
        "  \"\"\"Builds the generator by model name.\"\"\"\n",
        "  gan_type = MODEL_POOL[model_name]['gan_type']\n",
        "  if gan_type == 'stylegan':\n",
        "    generator = StyleGANGenerator(model_name)\n",
        "  return generator\n",
        "\n",
        "\n",
        "def imshow(images, col, viz_size=256):\n",
        "  \"\"\"Shows images in one figure.\"\"\"\n",
        "  # Extracting the Shape of the Images\n",
        "  num, height, width, channels = images.shape\n",
        "  #Ensures that the number of images (num) is divisible by the number of columns (col).\n",
        "  #This makes sure that the images can be arranged into a complete grid without leaving any empty cells.\n",
        "  assert num % col == 0\n",
        "  #Computes the number of rows needed to fit all the images in the grid.\n",
        "  row = num // col\n",
        "\n",
        "  #Creates an empty canvas (a blank image) to hold all the images in a grid format.\n",
        "  #The canvas has dimensions (viz_size * row, viz_size * col, channels), where:\n",
        "  #viz_size * row: Total height of the grid.\n",
        "  #viz_size * col: Total width of the grid.\n",
        "  #channels: Number of color channels (same as the input images).\n",
        "  fused_image = np.zeros((viz_size * row, viz_size * col, channels), dtype=np.uint8)\n",
        "\n",
        "  #Placing Each Image on the Canvas\n",
        "  for idx, image in enumerate(images):\n",
        "    i, j = divmod(idx, col)\n",
        "    y = i * viz_size\n",
        "    x = j * viz_size\n",
        "    #Resizing and Copying Each Image to the Canvas\n",
        "    if height != viz_size or width != viz_size:\n",
        "      image = cv2.resize(image, (viz_size, viz_size))\n",
        "    fused_image[y:y + viz_size, x:x + viz_size] = image\n",
        "\n",
        "  #Converting the Canvas to a Displayable Format\n",
        "  fused_image = np.asarray(fused_image, dtype=np.uint8)\n",
        "  data = io.BytesIO()\n",
        "  PIL.Image.fromarray(fused_image).save(data, 'jpeg')\n",
        "  im_data = data.getvalue()\n",
        "  #Displaying the Image Using IPython\n",
        "  disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  return disp"
      ],
      "metadata": {
        "id": "-s7RBNULp0Xy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select a Model"
      ],
      "metadata": {
        "id": "SE18UQjbqHuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This line is a special Jupyter Notebook cell annotation for display and auto-run in notebooks\n",
        "#@title { display-mode: \"form\", run: \"auto\" }\n",
        "\n",
        "# Fixed parameters\n",
        "model_name = \"stylegan_ffhq\"  # Always use 'stylegan_ffhq'\n",
        "latent_space_type = \"W\"       # Always use latent space type 'W'\n",
        "\n",
        "# Function to build and load the generator model\n",
        "generator = build_generator(model_name)\n",
        "\n",
        "# List of attributes for manipulation\n",
        "ATTRS = ['age', 'eyeglasses', 'gender', 'pose', 'smile']\n",
        "# Dictionary to store attribute boundaries\n",
        "boundaries = {}\n",
        "\n",
        "# Loading Attribute Boundaries\n",
        "for attr_name in ATTRS:\n",
        "    boundary_name = f'{model_name}_{attr_name}'\n",
        "    # Load the correct boundary file based on the latent space type\n",
        "    boundary_path = f'boundaries/{boundary_name}_w_boundary.npy'\n",
        "    boundaries[attr_name] = np.load(boundary_path)\n"
      ],
      "metadata": {
        "id": "8jeFZnt3qBqw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload latent codes"
      ],
      "metadata": {
        "id": "eVYhSVzVqS5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Upload the .npy file\n",
        "print(\"[INFO] Please upload your latent vector (.npy file):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the uploaded latent vector\n",
        "npy_file_name = list(uploaded.keys())[0]\n",
        "latent_codes = np.load(npy_file_name)\n",
        "\n",
        "# Ensure that the latent vector is in the correct format (numpy.ndarray) and shape\n",
        "if not isinstance(latent_codes, np.ndarray) or latent_codes.shape != (1, 512):\n",
        "    raise ValueError(f\"Latent codes must be a numpy.ndarray with shape (1, 512), but got {latent_codes.shape}\")\n",
        "\n",
        "# Use W space for StyleGAN synthesis\n",
        "synthesis_kwargs = {'latent_space_type': 'W'}\n",
        "\n",
        "# Generate the image using your custom latent vector\n",
        "images = generator.easy_synthesize(latent_codes, **synthesis_kwargs)['image']\n",
        "\n",
        "# Display the generated images using your imshow function\n",
        "imshow(images, col=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "L1t9sQI7qXFe",
        "outputId": "fde24e48-7694-4500-82bd-5b0d582c0134"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Please upload your latent vector (.npy file):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f35adca-c3dc-43f9-86a1-aa0465d4f2fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f35adca-c3dc-43f9-86a1-aa0465d4f2fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving your_latent_vector.npy to your_latent_vector (4).npy\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Noise"
      ],
      "metadata": {
        "id": "q538xAYyqe5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Differential Privacy Parameters (Slider Values)\n",
        "epsilon = 5  # @param {\"type\":\"slider\",\"min\":0.01,\"max\":5,\"step\":0.01}\n",
        "delta = 0.001  # @param {type:\"slider\", min:1e-7, max:1e-3, step:1e-7}\n",
        "clipping_threshold = 0.1  # @param {type:\"slider\", min:0.1, max:5.0, step:0.1}\n",
        "\n",
        "# Dropdown Menu for Attribute Selection\n",
        "attribute_selection = \"Age\"  # @param [\"Age\", \"Gender\", \"Both\"]\n",
        "\n",
        "# Sliders for the Selected Attributes\n",
        "if attribute_selection in [\"Age\", \"Both\"]:\n",
        "    age = 1  # @param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
        "else:\n",
        "    age = 0  # Disable age if not selected\n",
        "\n",
        "if attribute_selection in [\"Gender\", \"Both\"]:\n",
        "    gender = 1  # @param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
        "else:\n",
        "    gender = 0  # Disable gender if not selected\n",
        "\n",
        "# Function to add Gaussian noise for differential privacy\n",
        "def add_gaussian_noise(epsilon, delta, boundary):\n",
        "    \"\"\"\n",
        "    Adds Gaussian noise to a vector for differential privacy.\n",
        "\n",
        "    Args:\n",
        "        epsilon (float): Privacy budget.\n",
        "        delta (float): Probability of failure.\n",
        "        boundary (np.ndarray): Attribute boundary vector.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Noise scaled by boundary.\n",
        "    \"\"\"\n",
        "    # Compute the standard deviation for Gaussian noise\n",
        "    sigma = np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n",
        "\n",
        "    # Generate Gaussian noise\n",
        "    noise = np.random.normal(0, sigma, boundary.shape)\n",
        "\n",
        "    # Return the noise scaled by the boundary\n",
        "    return boundary * noise\n",
        "\n",
        "# Copy the original latent codes\n",
        "new_codes = latent_codes.copy()\n",
        "\n",
        "# Add noise only to the selected attributes\n",
        "for attr_name in [\"age\", \"gender\"]:  # Only iterate over selected attributes\n",
        "    attr_value = eval(attr_name)  # Get the slider value for the current attribute\n",
        "\n",
        "    # Skip attributes with a slider value of 0\n",
        "    if attr_value == 0:\n",
        "        continue\n",
        "\n",
        "    # Add Gaussian noise to the boundary\n",
        "    noised_boundary = add_gaussian_noise(\n",
        "        epsilon=epsilon,\n",
        "        delta=delta,\n",
        "        boundary=boundaries[attr_name]\n",
        "    )\n",
        "\n",
        "    # Add the noise-modified boundary to the latent codes\n",
        "    new_codes += noised_boundary * attr_value\n",
        "\n",
        "# Apply clipping as the final step\n",
        "new_codes = np.clip(new_codes, -clipping_threshold, clipping_threshold)\n",
        "\n",
        "# Generate and display the new images\n",
        "new_images = generator.easy_synthesize(new_codes, **synthesis_kwargs)['image']\n",
        "imshow(new_images, col=num_samples)\n"
      ],
      "metadata": {
        "id": "Ic-vCQ6qqj0U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}